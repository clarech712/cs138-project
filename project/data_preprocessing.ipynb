{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook\n",
    " \n",
    "This notebook focuses on preparing raw job description data for analysis. It includes steps for cleaning, transforming, and structuring the data to make it suitable for machine learning models or other analytical techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_tools import DataFrameSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 [Kaggle - Data Analyst Job Postings Google Search](https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search)\n",
    "*gsearch_jobs.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>commute_time</th>\n",
       "      <th>salary_pay</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst (Remote)</td>\n",
       "      <td>KGS Technology Group</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Built In</td>\n",
       "      <td>Job Description\\n\\nFull-Time...\\n\\nWe are look...</td>\n",
       "      <td>['22 hours ago', 'Work from home', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgKFJlbW90ZS...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tableau', 'javascript', 'python', 'power_bi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst with BA - Full Time</td>\n",
       "      <td>Talent Group</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Qualifications :\\n• 5+ Work experience as a da...</td>\n",
       "      <td>['4 hours ago', 'Work from home', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3Qgd2l0aCBCQS...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ClarisHealth</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>You may be ideal for this position if...\\n• Yo...</td>\n",
       "      <td>['6 hours ago', 'Work from home', 'Full-time',...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['postgres', 'mysql', 'postgresql', 'mongo', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                             title          company_name  \\\n",
       "0           0      0             Data Analyst (Remote)  KGS Technology Group   \n",
       "1           1      1  Data Analyst with BA - Full Time          Talent Group   \n",
       "2           2      2                      Data Analyst          ClarisHealth   \n",
       "\n",
       "     location           via  \\\n",
       "0   Anywhere   via Built In   \n",
       "1   Anywhere   via LinkedIn   \n",
       "2   Anywhere   via LinkedIn   \n",
       "\n",
       "                                         description  \\\n",
       "0  Job Description\\n\\nFull-Time...\\n\\nWe are look...   \n",
       "1  Qualifications :\\n• 5+ Work experience as a da...   \n",
       "2  You may be ideal for this position if...\\n• Yo...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0    ['22 hours ago', 'Work from home', 'Full-time']   \n",
       "1     ['4 hours ago', 'Work from home', 'Full-time']   \n",
       "2  ['6 hours ago', 'Work from home', 'Full-time',...   \n",
       "\n",
       "                                              job_id  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgKFJlbW90ZS...   \n",
       "1  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3Qgd2l0aCBCQS...   \n",
       "2  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "\n",
       "                                           thumbnail  ... commute_time  \\\n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "2  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "\n",
       "  salary_pay salary_rate salary_avg salary_min salary_max salary_hourly  \\\n",
       "0        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "1        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "2        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "\n",
       "   salary_yearly salary_standardized  \\\n",
       "0            NaN                 NaN   \n",
       "1            NaN                 NaN   \n",
       "2            NaN                 NaN   \n",
       "\n",
       "                                  description_tokens  \n",
       "0  ['tableau', 'javascript', 'python', 'power_bi'...  \n",
       "1                                            ['sql']  \n",
       "2  ['postgres', 'mysql', 'postgresql', 'mongo', '...  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_df = pd.read_csv('../kaggle_datasets/gsearch_jobs.csv', nrows=100)\n",
    "gsearch_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DataFrame Overview\n",
      "========================================\n",
      "Shape: (100, 4)\n",
      "Size: 400\n",
      "Number of Columns: 4\n",
      "Memory Usage: 0.75 MB\n",
      "\n",
      "Columns:\n",
      "- title\n",
      "- description\n",
      "- extensions\n",
      "- description_tokens\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Column Details\n",
      "========================================\n",
      "\n",
      "Column: title\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 55\n",
      "\n",
      "Column: description\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 78\n",
      "\n",
      "Column: extensions\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 69\n",
      "\n",
      "Column: description_tokens\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 61\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DataFrameSummarizer(gsearch_df[['title', 'description', 'extensions', 'description_tokens']]).get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tableau', 'javascript', 'python', 'power_bi', 'spss', 'sql', 'r', 'excel', 'sas']\n",
      "['sql']\n",
      "['postgres', 'mysql', 'postgresql', 'mongo', 'c', 't-sql', 'sql']\n",
      "['aws', 'sql', 'sas']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cbrad\\AppData\\Local\\Temp\\ipykernel_20188\\1375918093.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(dt[-1][-1])\n"
     ]
    }
   ],
   "source": [
    "# This data comes with pre-mined skills for some fraction of the datapoints\n",
    "for dt in gsearch_df[['description_tokens']][:5].iterrows():\n",
    "    print(dt[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Summary...\n",
      "\n",
      "What you'll do...\n",
      "\n",
      "As a Senior Data Analyst within the Supply Chain department, you will play a critical role in analyzing and interpreting vast datasets to extract valuable insights that inform strategic decisions. Leveraging your expertise in data analytics and your in-depth understanding of supply chain processes, you will collaborate with cross-functional teams to identify opportunities for optimization, cost reduction, and process enhancements.\n",
      "\n",
      "What you'll do:\n",
      "• Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function, collaborating with stakeholders to understand business goals, processes, and requirements.\n",
      "• Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Conduct data discovery, analysis, and validation between different data sources and systems. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.\n",
      "• Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.\n",
      "• Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Connect data and provide insights based on data and work with stakeholders to continuously simplify or enhance processes, such as operational adjustments. Proactively identify opportunities for process improvement, automation, and optimization. Respond to complex and time-sensitive inquiries.\n",
      "• Data Quality Management: Promotes and educates others on data quality awareness. Manages data quality issues and leads data cleansing activities to remove data quality defects, improve data quality, and eliminate unused data. Profiles, analyzes, and assesses data quality. Tests and validates data quality requirements. Continuously measures and monitors data quality. Delivers against data quality service level agreements. Partner with data stewards and owners to apply data governance standards and practices. Collaborate with technology partners to diagnose and resolve potential data issues. Determines user accessibility and removes or restricts user access as needed. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines.\n",
      "• Data Visualization: Generates appropriate graphical representations of data and model outcomes. Understands customer requirements to design appropriate data representation for multiple data sets. Work with User Experience designers and User Interface engineers as required to build front end applications. Presents to and influences the team and business audience using the appropriate frameworks and conveys clear messages through business and stakeholder understanding. Customizes communication style based on stakeholder under guidance and leverages rational arguments. Guides and mentors junior associates on story types, structures, and techniques based on context. Develop reports and dashboards to address stakeholders' key concerns and enable data-driven decision-making.\n",
      "• Exploratory Data Analysis: Collects and tabulates data and evaluates results to determine accuracy, validity, and applicability. Supports the identification and application of statistical techniques based on requirements. Applies suitable technique under direction from leadership. Assists in the planning, design and implementation of exploratory data analysis research projects. Understands existing statistical models and identifies and recommends statistical models based on hypothesis. Conducts statistical experiments (for example hypothesis tests, confidence intervals) and builds basic statistical models using tools such as Python & R. Uses advanced knowledge in data discovery tools to write queries and analyzes data to identify patterns, trends, outliers, and correlations.\n",
      "• Identify potential risks related to process and system changes.\n",
      "• Coordinates, completes, and oversees job-related activities and assignments by developing and maintaining relationships with key stakeholders; supporting plans and initiatives to meet customer and business needs; identifying and communicating goals and objectives; building accountability for and measuring progress in achieving results; identifying and addressing improvement opportunities; and demonstrating adaptability and promoting continuous learning.\n",
      "What you'll bring:\n",
      "• Bachelor's degree in Data Science, Statistics, Supply Chain Management, or a related field. Master's degree preferred.\n",
      "• Proven experience (5+ years) as a Data Analyst within a supply chain or logistics environment.\n",
      "• Proficient in SQL for data querying and analysis.\n",
      "• Expertise in data visualization tools - Tableau (preferred) or Power BI - to present complex information in a clear and concise manner.\n",
      "• Python a plus but not required.\n",
      "• Familiarity with ERP systems and data integration techniques.\n",
      "• Solid analytical and problem-solving skills with a detail-oriented approach.\n",
      "• Excellent communication and presentation abilities, with the ability to interact effectively with both technical and non-technical stakeholders.\n",
      "• Demonstrated ability to lead and manage projects independently and as part of a team.\n",
      "• Strong organizational skills and ability to handle multiple priorities in a fast-paced environment.\n",
      "• Experience with advanced statistical modeling and forecasting techniques.\n",
      "• Knowledge of machine learning algorithms and applications within the supply chain domain.\n",
      "• Familiarity with data warehousing and data engineering concepts.\n",
      "The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\n",
      "\n",
      "Benefits & Perks:\n",
      "\n",
      "Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\n",
      "\n",
      "Equal Opportunity Employer:\n",
      "\n",
      "Sam's Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.\n",
      "\n",
      "Minimum Qualifications...\n",
      "\n",
      "Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n",
      "\n",
      "Option 1: Bachelor's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Arts, Finance or related field and 2 years'\n",
      "experience in data analysis, data science, statistics, or related field. Option 2: Master's degree in Business, Engineering, Statistics, Economics,\n",
      "Analytics, Mathematics, Computer Science, Information Technology or related field. Option 3: 4 years' experience in data analysis, data science,\n",
      "statistics, or related field.\n",
      "\n",
      "Preferred Qualifications...\n",
      "\n",
      "Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n",
      "\n",
      "Data science, data analysis, statistics, or related field, Master's degree in Business, Computer Science, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field, Related industry experience (for example, retail, merchandising, healthcare, eCommerce), Successful completion of assessments in data analysis and Business Intelligence tools and scripting languages (for example, SQL, Python, Spark, Scala, R, Power BI, or Tableau)\n",
      "\n",
      "Primary Location...\n",
      "2101 SE SIMPLE SAVINGS DR, BENTONVILLE, AR 72712-4304, United States of America\n"
     ]
    }
   ],
   "source": [
    "# The job descriptions seem to be raw job descriptions. No pre-processing.\n",
    "print(gsearch_df.sample().description.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 [Kaggle - LinkedIn Job Postings](https://www.kaggle.com/datasets/arshkon/linkedin-job-postings)\n",
    "*postings.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            company_name                              title  \\\n",
       "0    921716   Corcoran Sawyer Smith              Marketing Coordinator   \n",
       "1   1829192                     NaN  Mental Health Therapist/Counselor   \n",
       "2  10998357  The National Exemplar         Assitant Restaurant Manager   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
       "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
       "\n",
       "           location  company_id  views  med_salary  ...  \\\n",
       "0     Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
       "1  Fort Collins, CO         NaN    1.0         NaN  ...   \n",
       "2    Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
       "\n",
       "                                         skills_desc   listed_time  \\\n",
       "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1                                                NaN  1.712858e+12   \n",
       "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "\n",
       "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
       "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "\n",
       "  normalized_salary  zip_code     fips  \n",
       "0           38480.0    8540.0  34021.0  \n",
       "1           83200.0   80521.0   8069.0  \n",
       "2           55000.0   45202.0  39061.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_df = pd.read_csv('../kaggle_datasets/postings.csv', nrows=100)\n",
    "linkedin_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DataFrame Overview\n",
      "========================================\n",
      "Shape: (100, 3)\n",
      "Size: 300\n",
      "Number of Columns: 3\n",
      "Memory Usage: 0.47 MB\n",
      "\n",
      "Columns:\n",
      "- title\n",
      "- description\n",
      "- skills_desc\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Column Details\n",
      "========================================\n",
      "\n",
      "Column: title\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 96\n",
      "\n",
      "Column: description\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 100\n",
      "\n",
      "Column: skills_desc\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 90\n",
      "  - Percentage of Missing Values: 90.00%\n",
      "  - Number of Unique Values: 10\n",
      "  - Unique Values: ['Requirements: \\n\\nWe are seeking a College or Graduate Student (can also be completed with school) with a focus in Planning, Architecture, Real Estate Development or Management or General Business. Must be able to work in an extremely fast paced environment and able to multitask and prioritize.'\n",
      " nan\n",
      " 'We are currently accepting resumes for FOH - Asisstant Restaurant Management with a strong focus on delivering high quality customer service. Prefer 1 to 3 years FOH management experience. Candidate should be a self-starter, proactive, attentive to details and like developing others. Must have a strong sense of teamwork and strong witten and verbal communication skills. Have a keen interest in service, food and learning. Passion for excellence and doing things right.'\n",
      " 'This position requires a baseline understanding of online marketing including Search Engine Marketing, Search Engine Optimization, and campaign analytics. The ideal candidate must be an analytical and detailed dynamic, self-starter who is proactive, and able to multitask effectively. This individual must be a strategic thinker with excellent verbal and written communication, as well strong presentation skills and the ability to work independently in an organized manner.'\n",
      " '• Requires the ability to communicate effective, both verbally and in writing • Requires basic computer skills \\n\\nEDUCATION AND EXPERIENCE: \\n\\n• Graduate of an accredited school of occupational therapy • Must possess current valid Nebraska State License in Occupational Therapy • Must possess current valid registration by the NBCOT ( National Board for Certification in Occupational Therapy) • Must be certified in Basic Life Support • Experience with pediatric patients preferred'\n",
      " 'Knowledge, Skills and Abilities: 1. Proficient with computer technology such as Microsoft Office. Also proficiency with (or ability to learn) ProPresenter and online applications such as Google Calendar and Planning center. Understanding and skill in Photoshop, Adobe Premiere a plus.\\n 2. Good writing, analytical and problem‐solving skills.\\n 3. Good knowledge of social networking applications such as Facebook, Twitter.\\n 4. Ability to communicate effectively verbally and in writing.\\n 5. Ability to operate standard office equipment, including but not limited to, computers, telephone systems, copiers/printers and facsimile machines.\\n 6. Ability to follow oral and written instructions.\\n 7. Follow-up skills with great attention to detail.\\n 8. Coachable ability in graphic design and minimal video editing ability a HUGE plus and preferred, but not required. \\nMinimum Qualifications: 1. At least two (2) years of experience in general office responsibilities and procedures and two (2) years of graphics design and media background.\\n 2. Must be proficient in computer usage, both internet and word processing.\\n 3. Knowledge of principles and practices of basic office management and organization.\\n 4. Ability to work well either alone or as part of a team.\\n 5. Must be fully committed to the mission of FBC Melbourne/Bay West Church'\n",
      " 'The Production Supervisor must possess strong leadership skills with a demonstrated ability to organize a team and its production processes to meet specific targets. A college degree and/or five to seven years related work experience is required. Knowledge of lean manufacturing concepts is also required. This person should also posses excellent communication and organizational skills. Computer competency is necessary, as well as good presentation and training skills.'\n",
      " 'Skills/Qualifications: Two-year or four-year degree in business or marketing and 0—2 years of previous experience. Position requires outstanding verbal skills and the ability to handle multiple tasks. Must be proficient in Microsoft Word, Outlook, Excel, Power Point, and Constant Contact. Social media knowledge and some graphic design skills would be a definite advantage. '\n",
      " 'Job Overview: Manage a project from start to finish under the supervision of a S.E. Manage personnel assisting in the project. Collaborate with fellow engineers to provide the most efficient, cost effective design. Understanding of current building codes. Work with the following software: Lpile, Risa, Ramsteel, Enercalc, Excel and similar software. Work with Architects and Contractors to discuss project requirements and quickly resolve issues. Analyze, design and detail structures, respond to plan check comments and manage construction administration. Perform field visits to document existing structures. Write reports. Perform field visit to fill out ASCE 31 checklists and analyze building buildings per ASCE 31 and ASCE 41.'\n",
      " 'Strong interpersonal communication skills and strong organizational skills are a must. Must be proficient in Microsoft Word, Excel and have excellent computer skills.'\n",
      " 'Data Entry Filing Receptionist Duties Customer Service Microsoft Word Microsoft Excel Calls Phone Etiquette Answer Telephone Skills Teamwork Microsoft Office Spreadsheets Appointment Scheduling Multi Tasking Multi-line Phone Office Equipment Customer Satisfaction Organization Skills Confidentiality Telephone Reception ']\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DataFrameSummarizer(linkedin_df[['title', 'description', 'skills_desc']]).get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position OverviewButler University's Office of Admission seeks a dynamic, experienced enrollment professional to join our team as a Midwest Regional Representative. The candidate must be detail-oriented, self-motivated, have excellent communication skills and the ability to articulate the values of Butler University.\n",
      "The Assistant Director of Admission, Midwest Regional will represent the university to prospective students and assists students and families in the enrollment process. This position is responsible for all aspects of recruitment for prospective first year and transfer students. This is a remote position with the ideal candidate living in, or willing to relocate on own, to Minnesota (Minneapolis/St. Paul Metro area).\n",
      "ResponsibilitiesExpand Butler University market position within the region and successfully support enrollment goals as established by University leadership Uses a strategic approach to territory management with guidance of the senior team to ensure steps are in place to meet enrollment goals Assists with the coordination of projects and programs as assigned Cultivate relationships with students, local school/college counselors, independent counselors, and community-based organizations in recruitment territory Review and holistically evaluate approximately 600-1000 applications for assigned territory Plan and execute data-driven travel based on demographic analyses, market research, and other admission data to high schools and college fairs in assigned territory; 25-100+ high school visits, 5-25+ college fairs, 10-40+ days of travel, including overnight travel Assist with various events at high schools such as application workshops and panel discussions Counsel constituents on the admission and financial aid process to support enrollment via phone, text, interview, campus visit programs, etc. Coordinate off-campus events and meetings for prospective/admitted students Host 4-6 weekly virtual meetings for families and students to connect Routinely travel to Indianapolis for training and recruitment events Assist with on campus events (Discover Butler, Open House, Butler Blue Scholars’ Day, etc.), HS counselor visit program, and Office of Admission and/or Enrollment Management Retreat Present and facilitate in-person and virtual Info Sessions and Admitted Student Visits Serve as primary liaison to other academic or student support offices, including supervisory role to secondary liaison Serve on an admission application review committee by specific College or US Match/Global MatchReview and make recommendations on applications for supplemental scholarship opportunities Interview students for scholarships (Butler Blue Scholars Day) Attend meetings, educational conferences, and training workshops Serve as member of regional ACAC Serve on new hire committees Plan interview schedule for potential candidates Present and facilitate specific sessions or workshops as part of on-campus events \n",
      "Required Qualifications A bachelor’s degree Two+ years’ college admission experience or other professional experience in working with college bound students Excellent oral and written communication skills including presentation skills Attention to detail and advanced organizational skills Experience in selective admission review processes Experience in database management and/or manipulation Strong teamwork skills for providing solutions Flexibility in a changing environment Willingness to work extra hours and/or weekends when needed Valid U.S. driver’s license, including ability to rent a car and use personal vehicle for local travel\n",
      "Preferred Qualifications Previous experience in admissions/enrollment management Knowledge of PeopleSoft, Slate or other Admission CRM Previous experience in multicultural recruitment, international admission, college access Experience working in financial aid or strong knowledge base of the financial aid process Fluent in Spanish Strategic Use of Slate Technolutions \n",
      "BU Benefits and PerksPlease check out Butler’s Total Rewards website to learn more about our benefit offerings, which include:Paid Time Off and Holidays:18 days of paid time off (vacation and PTO days)8 Paid HolidaysPaid Winter Break between Christmas Eve and New Year’s DayPaid Parental Leave (after 1 year of full-time employment)Health:Comprehensive medical, dental, and vision plans including disability and life insurance programsRetirement:10% employer contribution after 1 year of full-time employmentTuition Assistance:Remission of tuition for classes taken at Butler for employees, spouses, and dependent children.Eligibility after 9 months of full-time employmentEmployees & spouses- undergraduate/graduate degreesDependents (under age 26)- undergraduate degreeCovers tuition onlyTuition Exchange Program for DependentsButler Facilities Access, Discounts and Perks:Access to Butler’s on-site fitness facility and libraries for full-time staff and facultyLinkedIn Learning CoursesFree premium subscription to the Calm AppFree subscription to the WSJ and NYTDiscount at the College BookstoreDiscount on select Athletic and Arts/Events Center Performances\n",
      "About ButlerButler University is a private, nationally recognized comprehensive university encompassing six colleges: Arts, Business, Communication, Education, Liberal Arts & Sciences, and Pharmacy & Health Sciences. Approximately 4,500 undergraduate and 1,000 graduate and doctoral students are enrolled at Butler, representing 46 states and 24 countries.\n",
      "Join us at the crossroads of tradition & transformation. A career at Butler University means so much more than a job. Join the dedicated, innovative, and supportive community of faculty and staff that is moving Butler Beyond.\n",
      "Butler University is an equal-opportunity employer. We celebrate diversity and are committed to creating an inclusive and equitable environment for all employees. We welcome applications from all individuals, regardless of age, gender, gender identity, sex, race, religion, color, disability, protected veteran status, sexual orientation, national origin, or any other legally protected category.\n"
     ]
    }
   ],
   "source": [
    "# The job descriptions seem to be raw job descriptions. No pre-processing.\n",
    "print(linkedin_df.sample().description.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 [Kaggle - Data Analyst Jobs](https://www.kaggle.com/datasets/andrewmvd/data-analyst-jobs)\n",
    "*DataAnalyst.csv* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst, Center on Immigration and Justic...</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>Are you eager to roll up your sleeves and harn...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Vera Institute of Justice\\n3.2</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>1961</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Social Assistance</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Quality Data Analyst</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>Overview\\n\\nProvides analytical and technical ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Visiting Nurse Service of New York\\n3.8</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1893</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Health Care Services &amp; Hospitals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$2 to $5 billion (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior Data Analyst, Insights &amp; Analytics Team...</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>We’re looking for a Senior Data Analyst who ha...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Squarespace\\n3.4</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2003</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>GoDaddy</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Job Title  \\\n",
       "0           0  Data Analyst, Center on Immigration and Justic...   \n",
       "1           1                               Quality Data Analyst   \n",
       "2           2  Senior Data Analyst, Insights & Analytics Team...   \n",
       "\n",
       "              Salary Estimate  \\\n",
       "0  $37K-$66K (Glassdoor est.)   \n",
       "1  $37K-$66K (Glassdoor est.)   \n",
       "2  $37K-$66K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Are you eager to roll up your sleeves and harn...     3.2   \n",
       "1  Overview\\n\\nProvides analytical and technical ...     3.8   \n",
       "2  We’re looking for a Senior Data Analyst who ha...     3.4   \n",
       "\n",
       "                              Company Name      Location  Headquarters  \\\n",
       "0           Vera Institute of Justice\\n3.2  New York, NY  New York, NY   \n",
       "1  Visiting Nurse Service of New York\\n3.8  New York, NY  New York, NY   \n",
       "2                         Squarespace\\n3.4  New York, NY  New York, NY   \n",
       "\n",
       "                     Size  Founded       Type of ownership  \\\n",
       "0    201 to 500 employees     1961  Nonprofit Organization   \n",
       "1        10000+ employees     1893  Nonprofit Organization   \n",
       "2  1001 to 5000 employees     2003       Company - Private   \n",
       "\n",
       "                           Industry                  Sector  \\\n",
       "0                 Social Assistance              Non-Profit   \n",
       "1  Health Care Services & Hospitals             Health Care   \n",
       "2                          Internet  Information Technology   \n",
       "\n",
       "                      Revenue Competitors Easy Apply  \n",
       "0  $100 to $500 million (USD)          -1       True  \n",
       "1      $2 to $5 billion (USD)          -1         -1  \n",
       "2    Unknown / Non-Applicable     GoDaddy         -1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst = pd.read_csv('../kaggle_datasets/DataAnalyst.csv', nrows=100)\n",
    "data_analyst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DataFrame Overview\n",
      "========================================\n",
      "Shape: (100, 2)\n",
      "Size: 200\n",
      "Number of Columns: 2\n",
      "Memory Usage: 0.46 MB\n",
      "\n",
      "Columns:\n",
      "- Job Title\n",
      "- Job Description\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Column Details\n",
      "========================================\n",
      "\n",
      "Column: Job Title\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 64\n",
      "\n",
      "Column: Job Description\n",
      "  - Data Type: object\n",
      "  - Number of Missing Values: 0\n",
      "  - Percentage of Missing Values: 0.00%\n",
      "  - Number of Unique Values: 100\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DataFrameSummarizer(data_analyst[['Job Title', 'Job Description']]).get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Preliminary Modeling Strategy\n",
    "\n",
    "Given that all datasets include both job titles and descriptions, we can leverage both for data point representation. Here's a preliminary strategy for how we might approach this:\n",
    "\n",
    "*   **Job Titles:** Initially, I'm considering using FastText to generate embeddings for job titles.\n",
    "\n",
    "*   **Job Descriptions:** My plan is to use Gemini to extract key information, particularly skills, from the job descriptions. This extracted information will then inform the creation of a representation for the full description.\n",
    "\n",
    "A core idea I'm exploring is the concept of **skill-focused embeddings** – embeddings that are specifically trained or fine-tuned to emphasize skills. Several options exist:\n",
    "\n",
    "*   **BERT:** BERT offers both word and sentence tokenization capabilities. Word embeddings could be computationally intensive, but with access to Colab, I'm exploring attention mechanisms to mitigate this. Sentence embeddings offer a lighter alternative, although I'm still investigating how to effectively guide or steer sentence embeddings towards skill-centric representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "Before mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Moving Data to MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_mongo():\n",
    "    import utils.mongo_utils\n",
    "    reload(utils.mongo_utils)\n",
    "    # Import job data into MongoDB\n",
    "    import sys\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Add the parent directory to the Python path\n",
    "    parent_dir = Path.cwd().parent.absolute()\n",
    "    sys.path.append(str(parent_dir))\n",
    "\n",
    "\n",
    "    from utils.mongo_utils import MongoImporter\n",
    "    import utils.mongo_utils\n",
    "    reload(utils.mongo_utils)\n",
    "\n",
    "    # Set up parameters\n",
    "    db_name = \"rl_jobsdb\"\n",
    "    collection_name = \"all_jobs\"\n",
    "    db_path = \"../mongo_db/\"\n",
    "    directory_path = \"../kaggle_datasets/\"\n",
    "\n",
    "    # Create the importer with standard MongoDB URI\n",
    "    mongo_uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    # Create the importer\n",
    "    importer = MongoImporter(\n",
    "        mongo_uri=mongo_uri,\n",
    "        db_name=db_name,\n",
    "        collection_name=collection_name,\n",
    "        db_path=db_path\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Import all files\n",
    "        results = importer.import_all_files(directory_path)\n",
    "        print(\"Import completed. Results:\")\n",
    "        for file_name, count in results.items():\n",
    "            print(f\"{file_name}: {count} documents inserted\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing data: {str(e)}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        importer.close()\n",
    "        \n",
    "# insert_data_into_mongo()\n",
    "# Run only when needing to import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Backing Database Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-07 12:39:48,412 - __main__ - INFO - Backing up database 'rl_jobsdb' to ../mongo_db/\n",
      "2025-04-07 12:39:48,415 - utils.mongo_utils - INFO - Using provided mongo_path: C:\\Program Files\\MongoDB\\Server\\CMDTools_100.12.0\\bin\\mongodump.exe\n",
      "2025-04-07 12:39:48,421 - utils.mongo_utils - INFO - Clearing existing backup in C:\\Users\\cbrad\\OneDrive\\Documentos\\Tufts\\Spring 2025\\COMP138_ReinforcementLearning\\Final-Proj\\cs138-project\\mongo_db\n",
      "2025-04-07 12:39:48,564 - utils.mongo_utils - INFO - Running mongodump command: C:\\Program Files\\MongoDB\\Server\\CMDTools_100.12.0\\bin\\mongodump.exe --db rl_jobsdb --out C:\\Users\\cbrad\\OneDrive\\Documentos\\Tufts\\Spring 2025\\COMP138_ReinforcementLearning\\Final-Proj\\cs138-project\\mongo_db\n",
      "2025-04-07 12:39:54,754 - utils.mongo_utils - INFO - Successfully backed up database 'rl_jobsdb' to C:\\Users\\cbrad\\OneDrive\\Documentos\\Tufts\\Spring 2025\\COMP138_ReinforcementLearning\\Final-Proj\\cs138-project\\mongo_db\n",
      "2025-04-07 12:39:54,755 - utils.mongo_utils - INFO - Backup output: \n",
      "2025-04-07 12:39:54,756 - __main__ - INFO - Backup completed successfully\n"
     ]
    }
   ],
   "source": [
    "def backup_mongodb():\n",
    "    \"\"\"\n",
    "    Script to backup MongoDB database to a specified directory.\n",
    "    \"\"\"\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    import logging\n",
    "    from pathlib import Path\n",
    "    from utils.mongo_utils import MongoImporter as importer\n",
    "\n",
    "\n",
    "    from utils.mongo_utils import backup_mongodb\n",
    "    try:\n",
    "    # Set up logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        logger = logging.getLogger(__name__)\n",
    "\n",
    "        \"\"\"Main function to backup MongoDB database.\"\"\"\n",
    "        # Default values\n",
    "        db_name = \"rl_jobsdb\"\n",
    "        backup_path = \"../mongo_db/\"\n",
    "\n",
    "        logger.info(f\"Backing up database '{db_name}' to {backup_path}\")\n",
    "        mongodump_path = r\"C:\\Program Files\\MongoDB\\Server\\CMDTools_100.12.0\\bin\\mongodump.exe\"\n",
    "        # Perform the backup\n",
    "        success = backup_mongodb(db_name, backup_path, mongodump_path)\n",
    "\n",
    "        if success:\n",
    "            logger.info(\"Backup completed successfully\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        pass\n",
    "# Run only when needing to backup\n",
    "backup_mongodb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Mining Data Using Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limits\n",
    "Reate Limits\n",
    "| Model                                                      | RPM      | TPM       | RPD    | Context Size                                                                                                                                                                                                               |\n",
    "| ---------------------------------------------------------- | -------- | --------- | ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Gemini 2.5 Pro Experimental                                | 5        | 1,000,000 | 25     | 1,048,576 tokens[7](https://ai.google.dev/gemini-api/docs/models)                                                                                                                                                          |\n",
    "| Gemini 2.5 Pro Preview                                     | --       | --        | --     | 1,048,576 tokens[7](https://ai.google.dev/gemini-api/docs/models)                                                                                                                                                          |\n",
    "| Gemini 2.0 Flash                                           | 15       | 1,000,000 | 1,500  | 1,000,000 tokens[7](https://ai.google.dev/gemini-api/docs/models)                                                                                                                                                          |\n",
    "| Gemini 2.0 Flash Experimental (including image generation) | 10       | 1,000,000 | 1,500  | 1,000,000 tokens[7](https://ai.google.dev/gemini-api/docs/models)                                                                                                                                                          |\n",
    "| Gemini 2.0 Flash-Lite                                      | 30 green | 1,000,000 | 1,500  | 1,000,000 tokens[7](https://ai.google.dev/gemini-api/docs/models)                                                                                                                                                          |\n",
    "| Gemini 2.0 Flash Thinking Experimental 01-21               | 10       | 4,000,000 | 1,500  | Unknown                                                                                                                                                                                                                    |\n",
    "| Gemini 1.5 Flash                                           | 15       | 1,000,000 | 1,500  | Unknown                                                                                                                                                                                                                    |\n",
    "| Gemini 1.5 Flash-8B                                        | 15       | 1,000,000 | 1,500  | Unknown                                                                                                                                                                                                                    |\n",
    "| Gemini 1.5 Pro                                             | 2        | 32,000    | 50     | Up to **128K tokens** (standard), **1M tokens** (enterprise)[3](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)[5](https://blog.google/technology/ai/long-context-window-ai-models/) |\n",
    "| Imagen 3                                                   | --       | --        | --     | Unknown                                                                                                                                                                                                                    |\n",
    "| Gemma 3                                                    | 30       | 15,000    | 14,400 | Unknown                                                                                                                                                                                                                    |\n",
    "| Gemini Embedding Experimental                              | --       | --        | --     | Unknown                                                                                                                                                                                                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in the collection: 187394\n",
      "\n",
      "Fields in the collection: ['_id', 'doc_id', 'source_file', 'original_index', 'job_title', 'description', 'metadata']\n",
      "\n",
      "Data types of each field:\n",
      "- _id: ['objectId']\n",
      "- doc_id: ['string']\n",
      "- source_file: ['string']\n",
      "- original_index: ['int', 'long']\n",
      "- job_title: ['string']\n",
      "- description: ['double', 'string']\n",
      "- metadata: ['object']\n",
      "Error processing document with id: 67f2f280e93950df15184bd4\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f281e93950df15185248\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f284e93950df1518d514\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f286e93950df15190ccf\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f286e93950df1519102f\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f289e93950df1519761e\n",
      "Description: nan\n",
      "Error processing document with id: 67f2f289e93950df15197728\n",
      "Description: nan\n",
      "\n",
      "Average length of the 'description' field: 3627.95\n",
      "Standard deviation of the 'description' field: 2242.50\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"rl_jobsdb\"]\n",
    "collection = db[\"all_jobs\"]\n",
    "\n",
    "# Get total number of documents in the collection\n",
    "total_documents = collection.count_documents({})\n",
    "print(f\"Total documents in the collection: {total_documents}\")\n",
    "\n",
    "# Get a list of all fields in the collection\n",
    "fields = []\n",
    "for document in collection.find({}, limit=10):  # Limit to 10 documents for faster processing\n",
    "    for key in document.keys():\n",
    "        if key not in fields:\n",
    "            fields.append(key)\n",
    "\n",
    "print(f\"\\nFields in the collection: {fields}\")\n",
    "\n",
    "# Get data types of each field\n",
    "field_data_types = {}\n",
    "for field in fields:\n",
    "    # Use aggregation pipeline to get distinct data types for each field\n",
    "    data_types = collection.aggregate([\n",
    "        {\"$group\": {\n",
    "            \"_id\": {\"$type\": f\"${field}\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"type\": \"$_id\"\n",
    "        }}\n",
    "    ])\n",
    "    \n",
    "    # Extract the data types from the aggregation result\n",
    "    field_data_types[field] = [doc[\"type\"] for doc in data_types]\n",
    "\n",
    "print(\"\\nData types of each field:\")\n",
    "for field, types in field_data_types.items():\n",
    "    print(f\"- {field}: {types}\")\n",
    "\n",
    "# Calculate average length of the \"description\" field\n",
    "description_lengths = []\n",
    "for document in collection.find({}, {\"description\": 1}):\n",
    "    try:\n",
    "        if \"description\" in document:\n",
    "            description_lengths.append(len(document[\"description\"]))\n",
    "    except TypeError as e:\n",
    "        print(f\"Error processing document with id: {document.get('_id', 'Unknown ID')}\")\n",
    "        print(f\"Description: {document.get('description', 'No description')}\")\n",
    "\n",
    "if description_lengths:\n",
    "    average_description_length = np.mean(description_lengths)\n",
    "    average_description_std = np.std(description_lengths)\n",
    "    print(f\"\\nAverage length of the 'description' field: {average_description_length:.2f}\")\n",
    "    print(f\"Standard deviation of the 'description' field: {average_description_std:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo 'description' fields found in the documents.\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Shooting for 500,000 tokens an average of 4 characters per token, yields 2000000 characters.\n",
      "      To be on the safe side, 246.519453 would be the ideal numebr of jobs to send per request.\n",
      "      For a total of 764.873469 total requests.\n",
      "      At 245 jobs per request, at 30 requests per minute, it would take about 25.50 minutes.\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "      Shooting for 500,000 tokens an average of 4 characters per token, yields {500000*4} characters.\n",
    "      To be on the safe side, {2000000/(3627.95+2*2242.50):2f} would be the ideal numebr of jobs to send per request.\n",
    "      For a total of {187394/245:2f} total requests.\n",
    "      At 245 jobs per request, at 30 requests per minute, it would take about {(187394/245)*(1/30):.2f} minutes.\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 19:14:12,892 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-06 19:14:17,154 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 19:14:17,159 - google_genai.models - INFO - AFC remote call 1 is done.\n",
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```json\\n{\\n    \"67f2f276e93950df1517040f\": {\\n        \"technical_skills\": [\\n            \"SQL\",\\n            \"R\",\\n            \"Python\",\\n            \"AWS\",\\n            \"Caspio\",\\n            \"database management\",\\n            \"codebooks\",\\n            \"interactive dashboards\",\\n            \"data quality issues\",\\n            \"Git/GitHub\"\\n        ],\\n        \"soft_skills\": [\\n            \"data management skills\",\\n            \"commitment to immigrant\\'s rights\",\\n            \"hard-working\",\\n            \"creative\",\\n            \"attention to detail\",\\n            \"strong problem-solving ability\",\\n            \"logical reasoning skills\",\\n            \"work on multiple projects effectively and efficiently\",\\n            \"independently\",\\n            \"collaboratively with a team\"\\n        ],\\n        \"experience_requirements\": [\\n            \"1 2 years of professional or internship experience working with large datasets and preparing data for analysis.\",\\n            \"This position involves working with secure data that may require government security clearance.\",\\n            \"That clearance is restricted to U.S. citizens and citizens of countries that are party to collective defense agreements with the U.S.\",\\n            \"An additional requirement of that clearance is residence in the United States for at least three of the last five years.\"\\n        ]\\n    },\\n    \"67f2f276e93950df15170410\": {\\n        \"technical_skills\": [\\n            \"data extraction\",\\n            \"SQL\",\\n            \"PL/SQL\",\\n            \"relational databases\",\\n            \"MicroStrategy dashboard\",\\n            \"data storage\",\\n            \"Excel\",\\n            \"Access\",\\n            \"HEDIS\",\\n            \"QARR\",\\n            \"R\",\\n            \"SAS\",\\n            \"Stata\",\\n            \"statistical software\",\\n            \"Microsoft Word\",\\n            \"PowerPoint\",\\n            \"Excel\",\\n            \"Access\",\\n            \"data analysis\",\\n            \"data manipulation\",\\n            \"data validation\",\\n            \"databases\",\\n            \"dashboards\",\\n            \"macros\",\\n            \"software needs and applications\",\\n            \"error reports\"\\n        ],\\n        \"soft_skills\": [\\n            \"analytical and technical support\",\\n            \"communication\",\\n            \"interpersonal skills\",\\n            \"fast-paced environment\",\\n            \"non-technical audiences\",\\n            \"teamwork\",\\n            \"multi task\",\\n            \"oral\",\\n            \"written communication\"\\n        ],\\n        \"experience_requirements\": [\\n            \"Bachelors degree in bio/statistics, epidemiology, mathematics, computer science, social sciences, a related field or the equivalent work experience required.\",\\n            \"Masters degree with concentration in computer science, data science, or statistics preferred.\",\\n            \"Minimum of two years experience performing increasingly complex data analysis and interpretation, preferably in a managed care or health care setting, required.\",\\n            \"Experience with data extraction and manipulation required.\",\\n            \"Experience with relational databases and programming experience in SQL or PL/SQL required.\",\\n            \"Experience with claims data and health plan quality metrics (e.g., HEDIS, QARR) preferred.\",\\n            \"Proficiency conducting statistical analysis with R, SAS, Stata or other statistical software preferred.\",\\n            \"Advanced personal computer skills, including Microsoft Word, PowerPoint, Excel, and Access required.\",\\n            \"Effective oral, written communication and interpersonal skills required.\",\\n            \"Ability to multi task in a fast-paced environment required.\"\\n        ]\\n    }\\n}\\n```')], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1191, license=None, publication_date=None, start_index=954, title=None, uri='https://www.salary.com/research/salary/employer/vera-institute-of-justice/data-analyst-cij-salary'), Citation(end_index=1358, license=None, publication_date=None, start_index=1214, title=None, uri='https://www.salary.com/research/salary/employer/vera-institute-of-justice/data-analyst-cij-salary'), Citation(end_index=2678, license=None, publication_date=None, start_index=2512, title=None, uri='https://myjobsny.usnlx.com/BCE227BE56CF4F5ABDA6FA355700E91625/'), Citation(end_index=2761, license=None, publication_date=None, start_index=2552, title=None, uri='https://www.kaggle.com/code/cloudy17/data-analyst-jobs-eda'), Citation(end_index=3087, license=None, publication_date=None, start_index=2784, title=None, uri='https://myjobsny.usnlx.com/BCE227BE56CF4F5ABDA6FA355700E91625/'), Citation(end_index=3602, license=None, publication_date=None, start_index=2981, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=-0.10388304212712383, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash-lite' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=778, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=778)], prompt_token_count=2594, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=2594)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=3372) automatic_function_calling_history=[] parsed=None\n",
      "{'67f2f276e93950df1517040f': {'technical_skills': ['SQL', 'R', 'Python', 'AWS', 'Caspio', 'database management', 'codebooks', 'interactive dashboards', 'data quality issues', 'Git/GitHub'], 'soft_skills': ['data management skills', \"commitment to immigrant's rights\", 'hard-working', 'creative', 'attention to detail', 'strong problem-solving ability', 'logical reasoning skills', 'work on multiple projects effectively and efficiently', 'independently', 'collaboratively with a team'], 'experience_requirements': ['1 2 years of professional or internship experience working with large datasets and preparing data for analysis.', 'This position involves working with secure data that may require government security clearance.', 'That clearance is restricted to U.S. citizens and citizens of countries that are party to collective defense agreements with the U.S.', 'An additional requirement of that clearance is residence in the United States for at least three of the last five years.']}, '67f2f276e93950df15170410': {'technical_skills': ['data extraction', 'SQL', 'PL/SQL', 'relational databases', 'MicroStrategy dashboard', 'data storage', 'Excel', 'Access', 'HEDIS', 'QARR', 'R', 'SAS', 'Stata', 'statistical software', 'Microsoft Word', 'PowerPoint', 'Excel', 'Access', 'data analysis', 'data manipulation', 'data validation', 'databases', 'dashboards', 'macros', 'software needs and applications', 'error reports'], 'soft_skills': ['analytical and technical support', 'communication', 'interpersonal skills', 'fast-paced environment', 'non-technical audiences', 'teamwork', 'multi task', 'oral', 'written communication'], 'experience_requirements': ['Bachelors degree in bio/statistics, epidemiology, mathematics, computer science, social sciences, a related field or the equivalent work experience required.', 'Masters degree with concentration in computer science, data science, or statistics preferred.', 'Minimum of two years experience performing increasingly complex data analysis and interpretation, preferably in a managed care or health care setting, required.', 'Experience with data extraction and manipulation required.', 'Experience with relational databases and programming experience in SQL or PL/SQL required.', 'Experience with claims data and health plan quality metrics (e.g., HEDIS, QARR) preferred.', 'Proficiency conducting statistical analysis with R, SAS, Stata or other statistical software preferred.', 'Advanced personal computer skills, including Microsoft Word, PowerPoint, Excel, and Access required.', 'Effective oral, written communication and interpersonal skills required.', 'Ability to multi task in a fast-paced environment required.']}}\n"
     ]
    }
   ],
   "source": [
    "# Testing a single request\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils import SkillExtractor\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# MongoDB setup\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client.get_database(\"rl_jobsdb\")\n",
    "collection = db.get_collection(\"all_jobs\")\n",
    "\n",
    "# Fetch a single job document\n",
    "two_jobs = list(collection.find({}, {\"description\": 1, \"_id\": 1}).limit(2))\n",
    "\n",
    "# Convert _id to string for each job in two_jobs\n",
    "for job in two_jobs:\n",
    "    if \"_id\" in job:\n",
    "        job[\"_id\"] = str(job[\"_id\"])\n",
    "\n",
    "if two_jobs:\n",
    "    # Call SkillExtractor with the single job\n",
    "    print(SkillExtractor().extract_job_data(jobs=two_jobs))\n",
    "else:\n",
    "    print(\"No job found in the collection.\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with empty technical_skills 967\n",
      "Documents with non-empty technical_skills 11767\n",
      "Documents with skills 12734\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client.get_database(\"rl_jobsdb\")\n",
    "collection = db.get_collection(\"all_jobs\")\n",
    "\n",
    "# Fetch documents with empty technical_skills\n",
    "empty_skills_docs = list(collection.find({\"technical_skills\": []}))\n",
    "\n",
    "# Fetch documents with non-empty technical_skills\n",
    "skills_exists = list(collection.find({\"technical_skills\": {\"$exists\": True}}))\n",
    "non_empty_skills_docs = list(collection.find({\"technical_skills\": {\"$exists\": True, \"$not\": {\"$size\": 0}}}))\n",
    "\n",
    "\n",
    "print(f\"Documents with empty technical_skills {len(empty_skills_docs)}\")\n",
    "print(f\"Documents with non-empty technical_skills {len(non_empty_skills_docs)}\")\n",
    "print(f\"Documents with skills {len(skills_exists)}\")\n",
    "\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with empty technical_skills 180373\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client.get_database(\"rl_jobsdb\")\n",
    "collection = db.get_collection(\"all_jobs\")\n",
    "# Fetch documents with non-empty technical_skills\n",
    "no_skills = list(collection.find({\"technical_skills\": {\"$exists\": False}}))\n",
    "\n",
    "\n",
    "print(f\"Documents with empty technical_skills {len(no_skills)}\")\n",
    "\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
